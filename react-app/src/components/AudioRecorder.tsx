import React, { useState, useRef, useEffect, useCallback } from 'react';

interface AudioRecorderProps {
  onRecordingComplete: (audioBlob: Blob) => void;
  isRecording: boolean;
  onRecordingStart: () => void;
  onRecordingStop: () => void;
  continuousMode?: boolean;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onresult: ((event: any) => void) | null;
  onerror: ((event: any) => void) | null;
  onstart: (() => void) | null;
  onend: (() => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

const AudioRecorder: React.FC<AudioRecorderProps> = ({
  onRecordingComplete,
  isRecording,
  onRecordingStart,
  onRecordingStop,
  continuousMode = false
}) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [duration, setDuration] = useState(0);
  const [audioLevels, setAudioLevels] = useState<number[]>(Array(30).fill(0));
  const [micAccess, setMicAccess] = useState<'granted' | 'denied' | 'pending'>('pending');
  const [debugInfo, setDebugInfo] = useState<string>('ì‹œìŠ¤í…œ í™•ì¸ ì¤‘...');
  const [availableDevices, setAvailableDevices] = useState<MediaDeviceInfo[]>([]);
  const [selectedDeviceId, setSelectedDeviceId] = useState<string>('');

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const speechRecognitionRef = useRef<SpeechRecognition | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationRef = useRef<number | undefined>(undefined);
  const timerRef = useRef<NodeJS.Timeout | undefined>(undefined);

  // ê°œì„ ëœ íŒŒí˜• ì‹œê°í™”
  const updateAudioLevels = useCallback(() => {
    if (!analyserRef.current) return;

    const bufferLength = 512;
    const dataArray = new Uint8Array(bufferLength);
    analyserRef.current.getByteFrequencyData(dataArray);

    const newLevels = Array(30).fill(0).map((_, i) => {
      const start = Math.floor((i * bufferLength) / 30);
      const end = Math.floor(((i + 1) * bufferLength) / 30);
      const slice = dataArray.slice(start, end);
      const average = slice.reduce((sum, value) => sum + value, 0) / slice.length;
      
      const normalized = Math.min(100, (average / 128) * 100);
      return normalized > 5 ? normalized * (1 + Math.random() * 0.3) : normalized;
    });

    setAudioLevels(newLevels);
    animationRef.current = requestAnimationFrame(updateAudioLevels);
  }, []);

  // ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ì¥ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
  const getAvailableDevices = useCallback(async () => {
    try {
      console.log('ğŸ¤ ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ì¥ì¹˜ ê²€ìƒ‰...');
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      
      console.log('ğŸ¤ ë°œê²¬ëœ ë§ˆì´í¬ ì¥ì¹˜ë“¤:');
      audioInputs.forEach((device, index) => {
        console.log(`  ${index + 1}. ${device.label || `ë§ˆì´í¬ ${index + 1}`} (ID: ${device.deviceId})`);
      });
      
      setAvailableDevices(audioInputs);
      
      // ê¸°ë³¸ ì¥ì¹˜ ì„ íƒ
      if (audioInputs.length > 0 && !selectedDeviceId) {
        setSelectedDeviceId(audioInputs[0].deviceId);
        setDebugInfo(`ê¸°ë³¸ ë§ˆì´í¬: ${audioInputs[0].label || 'ë§ˆì´í¬ 1'}`);
      }
      
      return audioInputs;
    } catch (error) {
      console.error('âŒ ì¥ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:', error);
      setDebugInfo('ë§ˆì´í¬ ì¥ì¹˜ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      return [];
    }
  }, [selectedDeviceId]);

  // ê¶Œí•œ í™•ì¸ (ê°œì„ ë¨)
  const checkPermission = useCallback(async () => {
    console.log('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ì‹œì‘...');
    setDebugInfo('ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ì¤‘...');
    
    try {
      if (navigator.permissions) {
        try {
          const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
          console.log('ğŸ“‹ ê¶Œí•œ ìƒíƒœ:', result.state);
          setDebugInfo(`ê¶Œí•œ ìƒíƒœ: ${result.state}`);
          
          if (result.state === 'denied') {
            setMicAccess('denied');
            setDebugInfo('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.');
            return false;
          }
        } catch (e) {
          console.log('âš ï¸ ê¶Œí•œ API ì‚¬ìš© ë¶ˆê°€');
        }
      }

      setDebugInfo('ë§ˆì´í¬ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì¤‘...');
      
      // ë¨¼ì € ê¸°ë³¸ ë§ˆì´í¬ë¡œ í…ŒìŠ¤íŠ¸
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: { 
          echoCancellation: true, 
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      console.log('âœ… ë§ˆì´í¬ ì ‘ê·¼ ì„±ê³µ');
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length > 0) {
        const track = audioTracks[0];
        console.log('ğŸ¤ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬:', track.label);
        setDebugInfo(`í˜„ì¬ ë§ˆì´í¬: ${track.label || 'ê¸°ë³¸ ë§ˆì´í¬'}`);
      }
      
      stream.getTracks().forEach(track => track.stop());
      
      // ê¶Œí•œ íšë“ í›„ ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
      await getAvailableDevices();
      
      setMicAccess('granted');
      return true;
    } catch (error: any) {
      console.error('âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      setMicAccess('denied');
      
      if (error.name === 'NotAllowedError') {
        setDebugInfo('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.');
      } else if (error.name === 'NotFoundError') {
        setDebugInfo('ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      } else {
        setDebugInfo(`ë§ˆì´í¬ ì˜¤ë¥˜: ${error.message}`);
      }
      return false;
    }
  }, [getAvailableDevices]);

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  const initSpeechRecognition = useCallback(() => {
    console.log('ğŸ™ï¸ ìŒì„± ì¸ì‹ ì´ˆê¸°í™”...');
    
    const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
    if (!SpeechRecognition) {
      console.error('âŒ Web Speech API ì§€ì› ì•ˆë¨');
      setDebugInfo('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return null;
    }

    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'ko-KR';

    recognition.onstart = () => {
      console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘ë¨');
      setDebugInfo('ìŒì„± ì¸ì‹ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤');
    };

    recognition.onresult = (event) => {
      let finalTranscript = '';
      let interimTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        if (result.isFinal) {
          finalTranscript += result[0].transcript;
        } else {
          interimTranscript += result[0].transcript;
        }
      }

      const allText = finalTranscript + interimTranscript;
      setTranscript(allText);
      
      if (allText) {
        setDebugInfo(`ìŒì„± ì¸ì‹ ì¤‘: "${allText.slice(0, 30)}..."`);
      }

      // í™•ì¥ëœ ì¢…ë£Œ í‚¤ì›Œë“œ
      const endKeywords = [
        'ì´ìƒì…ë‹ˆë‹¤', 'ëì…ë‹ˆë‹¤', 'ë§ˆì¹©ë‹ˆë‹¤', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'ì™„ë£Œì…ë‹ˆë‹¤', 'ë‹¤í–ˆìŠµë‹ˆë‹¤',
        'ì´ìƒì´ì—ìš”', 'ëì´ì—ìš”', 'ì´ìƒ', 'ë', 'ì™„ë£Œ', 'ë§ˆì¹¨', 'ë‹µë³€ë', 'ë‹µë³€ ë',
        'ê·¸ë§Œ', 'ì—¬ê¸°ê¹Œì§€', 'ë‹¤ìŒ', 'ë„˜ì–´ê°€', 'ì´ë§Œ'
      ];

      if (finalTranscript && endKeywords.some(keyword => allText.includes(keyword))) {
        console.log('ğŸ¯ ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€:', allText);
        setDebugInfo('ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€ë¨ - ë…¹ìŒ ì¤‘ì§€');
        setTimeout(stopRecording, 500);
      }
    };

    recognition.onerror = (event) => {
      console.error('ğŸ¤ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      
      if (event.error === 'no-speech') {
        console.log('ğŸ”‡ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
        setDebugInfo('ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.');
        // no-speechëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ë…¹ìŒ ì¤‘ì§€í•˜ì§€ ì•ŠìŒ
        return;
      } else if (event.error === 'audio-capture') {
        setDebugInfo('ë§ˆì´í¬ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨');
        setMicAccess('denied');
      } else if (event.error === 'not-allowed') {
        setMicAccess('denied');
        setDebugInfo('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤');
      } else if (event.error === 'network') {
        setDebugInfo('ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ìŒì„± ì¸ì‹ ì‹¤íŒ¨');
      } else if (event.error === 'aborted') {
        console.log('ğŸ›‘ ìŒì„± ì¸ì‹ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤');
        return; // ì •ìƒì ì¸ ì¤‘ë‹¨
      } else {
        setDebugInfo(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`);
      }
    };

    recognition.onend = () => {
      console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì¢…ë£Œë¨');
      if (isListening && continuousMode) {
        console.log('ğŸ”„ ì—°ì† ëª¨ë“œ - ìŒì„± ì¸ì‹ ì¬ì‹œì‘');
        setTimeout(() => {
          if (speechRecognitionRef.current && isListening) {
            try {
              console.log('ğŸ”„ ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹œë„...');
              speechRecognitionRef.current.start();
              setDebugInfo('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ë¨');
            } catch (error: any) {
              console.warn('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹¤íŒ¨:', error);
              if (error.name === 'InvalidStateError') {
                console.log('ğŸ”„ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì‹œì‘í•  ìˆ˜ ì—†ëŠ” ìƒíƒœ');
                setDebugInfo('ìŒì„± ì¸ì‹ ìƒíƒœ ì˜¤ë¥˜ - ì¬ì‹œë„ ì¤‘...');
                // ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
                setTimeout(() => {
                  if (speechRecognitionRef.current && isListening) {
                    try {
                      speechRecognitionRef.current.start();
                    } catch (e) {
                      console.warn('ì¬ì‹œë„ë„ ì‹¤íŒ¨:', e);
                    }
                  }
                }, 1000);
              }
            }
          }
        }, 500); // 500ms í›„ ì¬ì‹œì‘ (ë” ì•ˆì •ì )
      }
    };

    return recognition;
  }, [isListening, continuousMode]);

  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    console.log('ğŸ¬ ë…¹ìŒ ì‹œì‘ ìš”ì²­');
    setDebugInfo('ë…¹ìŒ ì¤€ë¹„ ì¤‘...');
    
    if (!await checkPermission()) {
      console.error('âŒ ê¶Œí•œ í™•ì¸ ì‹¤íŒ¨');
      return;
    }

    try {
      const constraints = {
        audio: selectedDeviceId ? {
          deviceId: { exact: selectedDeviceId },
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        } : {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        }
      };
      
      console.log('ğŸ¤ ì„ íƒëœ ë§ˆì´í¬ë¡œ ìŠ¤íŠ¸ë¦¼ ìš”ì²­:', selectedDeviceId);
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      streamRef.current = stream;

      // ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜ í™•ì¸
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length > 0) {
        const track = audioTracks[0];
        console.log('ğŸ¤ ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬:', track.label);
        setDebugInfo(`ì‚¬ìš© ì¤‘: ${track.label || 'ë§ˆì´í¬'}`);
      }

      // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì„¤ì •
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 1024;
      analyser.smoothingTimeConstant = 0.3;
      source.connect(analyser);
      analyserRef.current = analyser;

      // MediaRecorder ì„¤ì •
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = () => {
        console.log('ğŸ¬ MediaRecorder ì¤‘ì§€ë¨');
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        onRecordingComplete(audioBlob);
      };

      // ìŒì„± ì¸ì‹ ì‹œì‘
      const recognition = initSpeechRecognition();
      if (recognition) {
        speechRecognitionRef.current = recognition;
        recognition.start();
      }

      mediaRecorder.start(500);
      updateAudioLevels();
      
      setIsListening(true);
      setDuration(0);
      setTranscript('');
      setDebugInfo('ë…¹ìŒ ì¤‘...');
      onRecordingStart();

      // íƒ€ì´ë¨¸ ì‹œì‘
      timerRef.current = setInterval(() => setDuration(prev => prev + 1), 1000);

    } catch (error: any) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      setDebugInfo(`ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ${error.message}`);
      setMicAccess('denied');
    }
  }, [checkPermission, initSpeechRecognition, onRecordingComplete, onRecordingStart, updateAudioLevels]);

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(() => {
    console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ìš”ì²­');
    
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
      animationRef.current = undefined;
    }
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = undefined;
    }
    
    if (speechRecognitionRef.current) {
      speechRecognitionRef.current.abort();
      speechRecognitionRef.current = null;
    }
    
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track: MediaStreamTrack) => {
        track.stop();
      });
      streamRef.current = null;
    }
    
    setIsListening(false);
    setAudioLevels(Array(30).fill(0));
    setDebugInfo('ë…¹ìŒ ì¤‘ì§€ë¨');
    onRecordingStop();
  }, [onRecordingStop]);

  // ìë™ ì‹œì‘/ì¤‘ì§€ ê´€ë¦¬
  useEffect(() => {
    if (continuousMode && isRecording && !isListening && micAccess === 'granted') {
      const timer = setTimeout(startRecording, 1000);
      return () => clearTimeout(timer);
    } else if (!isRecording && isListening) {
      stopRecording();
    }
  }, [continuousMode, isRecording, isListening, micAccess, startRecording, stopRecording]);

  useEffect(() => {
    checkPermission();
    return () => { 
      if (isListening) stopRecording(); 
    };
  }, [checkPermission, isListening, stopRecording]);

  const formatTime = (seconds: number) => `${Math.floor(seconds / 60)}:${(seconds % 60).toString().padStart(2, '0')}`;

  // ê°œì„ ëœ íŒŒí˜• ì»´í¬ë„ŒíŠ¸
  const WaveForm = () => (
    <div style={{ 
      display: 'flex', 
      alignItems: 'end', 
      justifyContent: 'center',
      gap: '2px', 
      height: '60px',
      marginBottom: '15px',
      padding: '0 20px'
    }}>
      {audioLevels.map((level, i) => (
        <div
          key={i}
          style={{
            width: '4px',
            height: `${Math.max(3, (level / 100) * 60)}px`,
            background: level > 15 
              ? `linear-gradient(to top, #4caf50 0%, #8bc34a 50%, #cddc39 100%)` 
              : '#e0e0e0',
            borderRadius: '2px',
            transition: 'all 0.1s ease',
            animation: level > 15 ? `wave-${i % 3} 0.8s ease-in-out infinite alternate` : 'none',
            opacity: level > 5 ? 1 : 0.5
          }}
        />
      ))}
    </div>
  );

  if (micAccess === 'denied') {
    return (
      <div style={{ textAlign: 'center', padding: '25px', background: '#ffebee', borderRadius: '15px', maxWidth: '500px' }}>
        <div style={{ fontSize: '48px', marginBottom: '15px' }}>ğŸ¤âŒ</div>
        <div style={{ color: '#d32f2f', fontWeight: 'bold', fontSize: '18px', marginBottom: '10px' }}>
          ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤
        </div>
        <div style={{ fontSize: '14px', color: '#666', marginBottom: '15px', padding: '10px', background: '#f5f5f5', borderRadius: '8px' }}>
          <strong>ë””ë²„ê·¸ ì •ë³´:</strong><br/>
          {debugInfo}
        </div>
        <div style={{ fontSize: '14px', color: '#666', marginBottom: '20px', lineHeight: '1.5' }}>
          1. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì™¼ìª½ì˜ ğŸ”’ ì•„ì´ì½˜ í´ë¦­<br/>
          2. ë§ˆì´í¬ ê¶Œí•œì„ "í—ˆìš©"ìœ¼ë¡œ ë³€ê²½<br/>
          3. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨<br/>
          <strong>Chrome ë¸Œë¼ìš°ì € ê¶Œì¥</strong>
        </div>
        <button onClick={checkPermission} style={{ 
          padding: '12px 24px', background: '#2196f3', color: 'white', 
          border: 'none', borderRadius: '8px', cursor: 'pointer', marginRight: '10px'
        }}>
          ê¶Œí•œ ë‹¤ì‹œ í™•ì¸
        </button>
        <button onClick={() => window.location.reload()} style={{ 
          padding: '12px 24px', background: '#4caf50', color: 'white', 
          border: 'none', borderRadius: '8px', cursor: 'pointer'
        }}>
          í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        </button>
      </div>
    );
  }

  return (
    <div style={{ display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '20px' }}>
      {/* ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ */}
      <div style={{ 
        fontSize: '12px', color: '#666', background: '#f8f9fa', 
        padding: '8px 12px', borderRadius: '8px', maxWidth: '400px', textAlign: 'center'
      }}>
        {debugInfo}
      </div>

      {/* ë§ˆì´í¬ ì¥ì¹˜ ì„ íƒ */}
      {availableDevices.length > 1 && micAccess === 'granted' && !isListening && (
        <div style={{
          background: '#e3f2fd', padding: '15px', borderRadius: '12px', 
          border: '2px solid #2196f3', maxWidth: '400px', width: '100%'
        }}>
          <div style={{ fontSize: '14px', fontWeight: 'bold', marginBottom: '10px', color: '#1976d2' }}>
            ğŸ¤ ë§ˆì´í¬ ì„ íƒ ({availableDevices.length}ê°œ ë°œê²¬)
          </div>
          <select
            value={selectedDeviceId}
            onChange={(e) => {
              setSelectedDeviceId(e.target.value);
              const selectedDevice = availableDevices.find(d => d.deviceId === e.target.value);
              setDebugInfo(`ì„ íƒë¨: ${selectedDevice?.label || 'ë§ˆì´í¬'}`);
            }}
            style={{
              width: '100%', padding: '8px', borderRadius: '6px', 
              border: '1px solid #2196f3', fontSize: '14px'
            }}
          >
            {availableDevices.map((device, index) => (
              <option key={device.deviceId} value={device.deviceId}>
                {device.label || `ë§ˆì´í¬ ${index + 1}`}
              </option>
            ))}
          </select>
          <div style={{ fontSize: '12px', color: '#666', marginTop: '8px' }}>
            ì›í•˜ëŠ” ë§ˆì´í¬ë¥¼ ì„ íƒí•œ í›„ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”
          </div>
        </div>
      )}

      {/* ìˆ˜ë™ ë…¹ìŒ ë²„íŠ¼ */}
      {!continuousMode && (
        <button
          onClick={isListening ? stopRecording : startRecording}
          disabled={micAccess !== 'granted'}
          style={{
            width: '120px', height: '120px', borderRadius: '50%', border: 'none',
            background: isListening 
              ? 'linear-gradient(45deg, #ff6b6b, #ee5a24)' 
              : 'linear-gradient(45deg, #667eea, #764ba2)',
            color: 'white', fontSize: '16px', fontWeight: 'bold',
            cursor: micAccess === 'granted' ? 'pointer' : 'not-allowed',
            boxShadow: isListening 
              ? '0 8px 25px rgba(255, 107, 107, 0.4)' 
              : '0 8px 25px rgba(102, 126, 234, 0.4)',
            animation: isListening ? 'pulse 1.5s infinite' : 'none'
          }}
        >
          {isListening ? 'â¹ï¸\në…¹ìŒ ì¤‘ì§€' : 'ğŸ¤\në…¹ìŒ ì‹œì‘'}
        </button>
      )}

      {/* ë…¹ìŒ ì¤‘ ìƒíƒœ */}
      {isListening && (
        <div style={{ 
          textAlign: 'center', padding: '25px', background: 'rgba(255,255,255,0.95)', 
          borderRadius: '20px', minWidth: '450px', boxShadow: '0 10px 30px rgba(0,0,0,0.15)',
          border: '3px solid #667eea' 
        }}>
          <div style={{ 
            color: '#ff6b6b', fontWeight: 'bold', marginBottom: '20px',
            display: 'flex', alignItems: 'center', justifyContent: 'center', gap: '12px', fontSize: '18px' 
          }}>
            <div style={{ 
              width: '12px', height: '12px', background: '#ff6b6b', 
              borderRadius: '50%', animation: 'pulse 1s infinite' 
            }} />
            ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
            <div style={{ 
              background: '#667eea', color: 'white', padding: '6px 15px', 
              borderRadius: '20px', fontSize: '16px' 
            }}>
              {formatTime(duration)}
            </div>
          </div>

          <WaveForm />

          <div style={{ 
            fontSize: '13px', marginBottom: '15px', fontWeight: 'bold',
            color: Math.max(...audioLevels) > 20 ? '#4caf50' : '#ff9800'
          }}>
            {Math.max(...audioLevels) > 20 ? 'ğŸ”Š ìŒì„±ì´ ì˜ ì¸ì‹ë˜ê³  ìˆìŠµë‹ˆë‹¤' : 'ğŸ”‡ ë” í¬ê³  ëª…í™•í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”'}
          </div>

          {transcript && (
            <div style={{ 
              fontSize: '16px', maxHeight: '100px', overflow: 'auto', padding: '15px',
              background: '#f8f9fa', borderRadius: '12px', marginBottom: '15px',
              border: '2px solid #e9ecef', lineHeight: '1.6' 
            }}>
              <div style={{ fontSize: '12px', color: '#666', marginBottom: '8px' }}>ğŸ’¬ ì‹¤ì‹œê°„ ì¸ì‹:</div>
              <div>"{transcript}"</div>
            </div>
          )}

          <div style={{ 
            fontSize: '13px', color: '#28a745', background: '#e8f5e9',
            padding: '10px 15px', borderRadius: '20px' 
          }}>
            ğŸ’¡ <strong>"ì´ìƒ"</strong>, <strong>"ë"</strong>, <strong>"ì™„ë£Œ"</strong> ë“±ì„ ë§í•˜ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
            <br />
            <div style={{ fontSize: '12px', marginTop: '5px', color: '#666' }}>
              ğŸ¤ ë§ˆì´í¬ê°€ ìŒì„±ì„ ê°ì§€í•˜ì§€ ëª»í•˜ë©´ ë” í¬ê³  ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”
            </div>
          </div>
        </div>
      )}

      <style>{`
        @keyframes pulse {
          0%, 100% { transform: scale(1); opacity: 1; }
          50% { transform: scale(1.05); opacity: 0.8; }
        }
        @keyframes wave-0 {
          0% { transform: scaleY(1); }
          100% { transform: scaleY(1.5); }
        }
        @keyframes wave-1 {
          0% { transform: scaleY(1.2); }
          100% { transform: scaleY(1.8); }
        }
        @keyframes wave-2 {
          0% { transform: scaleY(0.8); }
          100% { transform: scaleY(1.3); }
        }
      `}</style>
    </div>
  );
};

export default AudioRecorder;